{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS1SdiqdSuUp"
      },
      "source": [
        ""
      ],
      "id": "xS1SdiqdSuUp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i71U-gE8r5mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3748c2d3-6532-4a51-f59c-c79a59fbe1ac"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()  \n",
        "\n",
        "uinput_path = \"../content/DATA_CHAMBER_2021/\"\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Using CUDA\")"
      ],
      "id": "i71U-gE8r5mh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X8a2A1pr5pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619d4d78-fc4a-4e8b-85bc-5511e67d5a5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "6X8a2A1pr5pa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-DuwjQpr5r9"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/DATA_CHAMBER_2021.zip\" -d \"./\""
      ],
      "id": "A-DuwjQpr5r9",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7FN7WaSfID8"
      },
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "id": "l7FN7WaSfID8",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJyjxQ-mfIM1"
      },
      "source": [
        "tensor = transforms.ToTensor()\n",
        "resize = transforms.Resize(256)\n",
        "crop_224 = transforms.CenterCrop(224)\n",
        "crop_64 = transforms.CenterCrop(64)\n",
        "rotation = transforms.RandomRotation(degrees=20)\n",
        "blur = transforms.GaussianBlur(kernel_size=3)\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "def transform(type):\n",
        "  if(type == \"raw\"):\n",
        "    train_transform =  transforms.Compose([crop_224, tensor])\n",
        "    test_transform = transforms.Compose([resize, crop_224, tensor])\n",
        "  if(type == \"scale\"):\n",
        "    train_transform =  transforms.Compose([resize, crop_64, tensor])\n",
        "    test_transform = transforms.Compose([resize, crop_64, tensor])\n",
        "  if(type == \"preprocess\"):\n",
        "    train_transform =  transforms.Compose([resize, crop_224, blur, tensor])\n",
        "    test_transform = transforms.Compose([resize, crop_224, tensor])\n",
        "  if(type == \"augmentation\"):\n",
        "    train_transform =  transforms.Compose([resize, rotation, crop_224, tensor])\n",
        "    test_transform = transforms.Compose([resize, crop_224, tensor])\n",
        "  return train_transform, test_transform"
      ],
      "id": "hJyjxQ-mfIM1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9jXSa-hf3il"
      },
      "source": [
        "train_dataset_path = '../content/DATA_CHAMBER_2021/train'\n",
        "test_dataset_path = '../content/DATA_CHAMBER_2021/test'"
      ],
      "id": "R9jXSa-hf3il",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icb_0F7OwqGw"
      },
      "source": [
        "def prepare_dataset(train_transform, test_transform):\n",
        "  train_datasets = ImageFolderWithPaths(root = train_dataset_path, transform = train_transform)\n",
        "  test_datasets = ImageFolderWithPaths(root = test_dataset_path, transform = test_transform)\n",
        "  return train_datasets, test_datasets\n",
        "\n",
        "def prepare_dataloader(train_datasets, test_datasets):\n",
        "  train_loader = DataLoader(train_datasets, batch_size = 8, shuffle = True, num_workers = 2)\n",
        "  test_loader = DataLoader(test_datasets, batch_size = 8, shuffle = False, num_workers = 2)\n",
        "  return train_loader, test_loader"
      ],
      "id": "Icb_0F7OwqGw",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxsOj8JggQlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c6a9c0-3bad-4400-ef63-13df02754db2"
      },
      "source": [
        "def set_device():\n",
        "    if torch.cuda.is_available():\n",
        "        dev = \"cuda:0\"\n",
        "    else:\n",
        "        dev = \"cpu\"\n",
        "    return torch.device(dev)\n",
        "set_device()"
      ],
      "id": "LxsOj8JggQlJ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hXPkY9kvb3K"
      },
      "source": [
        "vgg16 = models.vgg19_bn(pretrained=True)\n",
        "vgg19 = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "def create_model(name_model):\n",
        "  if(name_model == \"vgg16\"):\n",
        "    vgg = vgg16\n",
        "  if(name_model == \"vgg19\"):\n",
        "    vgg = vgg19\n",
        "  for param in vgg.features.parameters():\n",
        "    param.require_grad = False\n",
        "  # Newly created modules have require_grad=True by default\n",
        "  num_features = vgg.classifier[6].in_features\n",
        "  features = list(vgg.classifier.children())[:-1] # Remove last layer\n",
        "  features.extend([nn.Linear(num_features, 3)]) # Add our layer with 4 outputs\n",
        "  vgg.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "  return vgg"
      ],
      "id": "-hXPkY9kvb3K",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdwWkFXtr576"
      },
      "source": [
        "def train_model(model, train_loader, train_datasets, criterion, optimizer, num_epochs):\n",
        "    train_batches = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        \n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for i,data in enumerate(train_loader):\n",
        "          inputs, labels,_ = data\n",
        "          print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          running_loss += loss.item() * inputs.size(0)\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "          epoch_loss = running_loss / len(train_datasets)\n",
        "          epoch_acc = running_corrects.double() / len(train_datasets)\n",
        "\n",
        "        print('{} loss: {:.4f}, acc: {:.4f}'.format(\"train\",\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model"
      ],
      "id": "NdwWkFXtr576",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZChYgPGNvAMg"
      },
      "source": [
        "def test_model(model, test_loader, criterion):\n",
        "    labels_input=list()\n",
        "    labels_output=list()\n",
        "    vid_id = list()\n",
        "        \n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for images, labels, fname in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels_input= labels_input + labels.tolist()\n",
        "        for f in fname:\n",
        "          vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n",
        "        outputs = model(images)\n",
        "            \n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "        labels_output= labels_output + preds.tolist()\n",
        "    return labels_input,labels_output, vid_id"
      ],
      "id": "ZChYgPGNvAMg",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LQ5dSHhhYbM"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "device = set_device()\n",
        "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "id": "7LQ5dSHhhYbM",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7OYLCShr6J_"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "import pandas as pd\n",
        "modelz = [\"vgg16\", \"vgg19\"]\n",
        "data = [\"raw\", \"scale\", \"preprocess\", \"augmentation\"]\n",
        "def main():\n",
        "  for namemodel in modelz:\n",
        "    models = create_model(name_model = namemodel)\n",
        "    device = set_device()\n",
        "    model = models.to(device)\n",
        "    for typ in data:\n",
        "      print(namemodel + \" - \" + typ + \":\\n\")\n",
        "      train_transform, test_transform = transform(type = typ)\n",
        "      train_datasets, test_datasets = prepare_dataset(train_transform, test_transform)\n",
        "      train_loader, test_loader = prepare_dataloader(train_datasets, test_datasets)\n",
        "      model = train_model(model, train_loader, train_datasets, criterion, optimizer_ft, num_epochs=5)\n",
        "      y_true,y_pred,vid_id = test_model(model,test_loader, criterion)\n",
        "      print(classification_report(y_true,y_pred))\n",
        "      accuracy_score(y_true, y_pred)\n"
      ],
      "id": "q7OYLCShr6J_",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJe0FMpUvoD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8359cae-3551-44c9-b3ba-8bb3d36e7341"
      },
      "source": [
        "main()"
      ],
      "id": "XJe0FMpUvoD5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16 - raw:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1476, acc: 0.3228\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1429, acc: 0.3384\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1472, acc: 0.3292\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1426, acc: 0.3356\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1446, acc: 0.3301\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.08      0.12       409\n",
            "           1       0.30      0.43      0.35       367\n",
            "           2       0.63      0.70      0.66       831\n",
            "\n",
            "    accuracy                           0.48      1607\n",
            "   macro avg       0.38      0.40      0.38      1607\n",
            "weighted avg       0.45      0.48      0.45      1607\n",
            "\n",
            "vgg16 - scale:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1848, acc: 0.3232\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1895, acc: 0.3245\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1867, acc: 0.3231\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1917, acc: 0.3216\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1934, acc: 0.3201\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.20      0.23       409\n",
            "           1       0.26      0.55      0.35       367\n",
            "           2       0.56      0.35      0.43       831\n",
            "\n",
            "    accuracy                           0.36      1607\n",
            "   macro avg       0.36      0.37      0.34      1607\n",
            "weighted avg       0.42      0.36      0.36      1607\n",
            "\n",
            "vgg16 - preprocess:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1398, acc: 0.3262\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1442, acc: 0.3097\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1389, acc: 0.3318\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1437, acc: 0.3234\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1413, acc: 0.3263\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.17      0.20       409\n",
            "           1       0.24      0.67      0.35       367\n",
            "           2       0.68      0.25      0.36       831\n",
            "\n",
            "    accuracy                           0.32      1607\n",
            "   macro avg       0.39      0.36      0.31      1607\n",
            "weighted avg       0.47      0.32      0.32      1607\n",
            "\n",
            "vgg16 - augmentation:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1372, acc: 0.3348\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1347, acc: 0.3317\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1384, acc: 0.3245\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1376, acc: 0.3314\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1402, acc: 0.3357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.05      0.08       409\n",
            "           1       0.25      0.62      0.36       367\n",
            "           2       0.66      0.49      0.56       831\n",
            "\n",
            "    accuracy                           0.41      1607\n",
            "   macro avg       0.39      0.38      0.33      1607\n",
            "weighted avg       0.46      0.41      0.39      1607\n",
            "\n",
            "vgg19 - raw:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1664, acc: 0.3067\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1605, acc: 0.3164\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1613, acc: 0.3088\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1633, acc: 0.3056\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1594, acc: 0.3103\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       409\n",
            "           1       0.21      0.39      0.27       367\n",
            "           2       0.52      0.58      0.55       831\n",
            "\n",
            "    accuracy                           0.39      1607\n",
            "   macro avg       0.24      0.32      0.27      1607\n",
            "weighted avg       0.32      0.39      0.35      1607\n",
            "\n",
            "vgg19 - scale:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1989, acc: 0.3347\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.2048, acc: 0.3286\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.2048, acc: 0.3295\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.2086, acc: 0.3170\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.2154, acc: 0.3126\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.03      0.05       409\n",
            "           1       0.21      0.26      0.23       367\n",
            "           2       0.49      0.64      0.55       831\n",
            "\n",
            "    accuracy                           0.40      1607\n",
            "   macro avg       0.29      0.31      0.28      1607\n",
            "weighted avg       0.35      0.40      0.35      1607\n",
            "\n",
            "vgg19 - preprocess:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1451, acc: 0.3399\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1469, acc: 0.3311\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1477, acc: 0.3286\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1480, acc: 0.3290\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training batch 840/840train loss: 1.1490, acc: 0.3259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.00      0.00       409\n",
            "           1       0.40      0.18      0.25       367\n",
            "           2       0.50      0.84      0.63       831\n",
            "\n",
            "    accuracy                           0.48      1607\n",
            "   macro avg       0.31      0.34      0.30      1607\n",
            "weighted avg       0.36      0.48      0.38      1607\n",
            "\n",
            "vgg19 - augmentation:\n",
            "\n",
            "Epoch 1/5\n",
            "----------\n",
            "Training batch 821/840"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6UWTtuUr6Mo"
      },
      "source": [
        ""
      ],
      "id": "D6UWTtuUr6Mo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXp5qnQr6Po"
      },
      "source": [
        ""
      ],
      "id": "_QXp5qnQr6Po",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgKYn5Vxr6SP"
      },
      "source": [
        ""
      ],
      "id": "XgKYn5Vxr6SP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXXMLhBvr6VQ"
      },
      "source": [
        ""
      ],
      "id": "DXXMLhBvr6VQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXjz6ve6r6Xs"
      },
      "source": [
        ""
      ],
      "id": "xXjz6ve6r6Xs",
      "execution_count": null,
      "outputs": []
    }
  ]
}